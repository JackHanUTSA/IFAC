%===============================================================================
% Sample bibliopgraphy file for ifaconf.bst style to be used in
% IFAC meeting papers
% Copyright (c) 2007-2008 International Federation of Automatic Control
%===============================================================================
@article{bhat2024grounding,
  title={Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback},
  author={Bhat, Vineet and Kaypak, Ali Umut and Krishnamurthy, Prashanth and Karri, Ramesh and Khorrami, Farshad},
  journal={CoRR},
  year={2024}
}

@article{liu2024enhancing,
  title={Enhancing the LLM-Based Robot Manipulation Through Human-Robot Collaboration},
  author={Liu, Haokun and Zhu, Yaonan and Kato, Kenji and Tsukahara, Atsushi and Kondo, Izumi and Aoyama, Tadayoshi and Hasegawa, Yasuhisa},
  journal={IEEE Robotics and Automation Letters},
  volume={9},
  number={8},
  pages={6904--6911},
  year={2024},
  publisher={IEEE}
}

@inproceedings{wang2024prompt,
  title={Prompt a robot to walk with large language models},
  author={Wang, Yen-Jen and Zhang, Bike and Chen, Jianyu and Sreenath, Koushil},
  booktitle={2024 IEEE 63rd Conference on Decision and Control (CDC)},
  pages={1531--1538},
  year={2024},
  organization={IEEE}
}
@inproceedings{xu2024penetrative,
  title={Penetrative ai: Making llms comprehend the physical world},
  author={Xu, Huatao and Han, Liying and Yang, Qirui and Li, Mo and Srivastava, Mani},
  booktitle={Proceedings of the 25th International Workshop on Mobile Computing Systems and Applications},
  pages={1--7},
  year={2024}
}

@inproceedings{yang2024llm,
  title={Llm-grounder: Open-vocabulary 3d visual grounding with large language model as an agent},
  author={Yang, Jianing and Chen, Xuweiyi and Qian, Shengyi and Madaan, Nikhil and Iyengar, Madhavan and Fouhey, David F and Chai, Joyce},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7694--7701},
  year={2024},
  organization={IEEE}
}


@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={                 30},
  year={2017}
}

@inproceedings{strobel2024llm2swarm,
  title={LLM2Swarm: Robot Swarms that Responsively Reason, Plan, and Collaborate through LLMs},
  author={Strobel, Volker and Dorigo, Marco and Fritz, Mario},
  booktitle={NeurIPS 2024 Workshop on Open-World Agents}
}
                 
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{liang2023code,
  title={Code as Policies: Language Model Programs for Embodied Control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2023},
  organization={IEEE}
}


@inproceedings{makoviychuk2isaac,
  title={Isaac Gym: High Performance GPU Based Physics Simulation For Robot Learning},
  author={Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and others},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)}
}

@inproceedings{mirchandanilarge,
  title={Large Language Models as General Pattern Machines},
  author={Mirchandani, Suvir and Xia, Fei and Florence, Pete and Driess, Danny and Arenas, Montserrat Gonzalez and Rao, Kanishka and Sadigh, Dorsa and Zeng, Andy and others},
  booktitle={7th Annual Conference on Robot Learning}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}


@inproceedings{tan2019lxmert,
  title={LXMERT: Learning Cross-Modality Encoder Representations from Transformers},
  author={Tan, Hao and Bansal, Mohit},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  year={2019},
  organization={Association for Computational Linguistics}
}

@inproceedings{huang2022language,
  title={Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  year={2022}
}

@inproceedings{huang2023inner,
  title={Inner Monologue: Embodied Reasoning through Planning with Language Models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  booktitle={Conference on Robot Learning},
  pages={1769--1782},
  year={2023},
  organization={PMLR}
}

@inproceedings{lin2023grounded,
  title={On grounded planning for embodied tasks with language models},
  author={Lin, Bill Yuchen and Huang, Chengsong and Liu, Qian and Gu, Wenda and Sommerer, Sam and Ren, Xiang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={11},
  pages={13192--13200},
  year={2023}
}