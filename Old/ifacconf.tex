%===============================================================================
% ifacconf.tex 2025-07-31 jpuente  
% 2022-11-11 jpuente change length of abstract
% 2025-07-31 jldiez added section on the use of AI
% Template for IFAC meeting papers
% Copyright (c) 2025 International Federation of Automatic Control
%===============================================================================
\documentclass{ifacconf}
\usepackage{stfloats}    % allows better placement for wide floats
% and then:
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}      % include this line if your document contains figures
%===============================================================================
\begin{document}
\begin{frontmatter}

\title{Dynamic Penetrative Trajectory Adaptation\thanksref{footnoteinfo}} 
% Title, preferably not more than 10 words.

\thanks[footnoteinfo]{This work was supported in part by the U.S. National Science Foundation (NSF) under Award No. 1826086.}

\author[First]{Zhifeng Han. Author} 
\author[Second]{Claire Walton. Author, Jr.} 


\address[First]{University of Texas at San Antonio, 
   San Antonio, TX 78249 USA (e-mail: zhifeng.han@utsa.edu).}
\address[Second]{University of Texas at San Antonio, 
   San Antonio, TX 78249 USA (e-mail: claire.walton@utsa.edu).}
%\address[Third]{Electrical Engineering Department, 
%   Seoul National University, Seoul, Korea, (e-mail: author@snu.ac.kr)}

\begin{abstract}                % Abstract of 50--100 words
DPTA is a conceptual framework where the LLM's world knowledge is leveraged to analyze low-level sensor feedback, enabling the dynamic selection and refinement of complex, pre-learned robot trajectories to achieve 
high dexterity and resilience in autonomous manipulation.
\end{abstract}

\begin{keyword}
LLM, robotic, Reinforcement Learning
\end{keyword}

\end{frontmatter}
%===============================================================

\section{Introduction}
interactive robots mission is a complex mission it need to nagvigate in complex and 
dynamic environment also need to fully flexable to planing the sequentially sub tasks. 
In order to achieve the goal we demo a method by utlize LLMs(large language model) and Reenforcement Learning. 
Our idea focuses on using an LLM's capacity for precise, short-horizon physical reasoning to 
dynamically select or modify the parameters of complex, learned robotic trajectories, 
effectively allowing the robot to autonomously execute tasks that previously required initial human intervention.
The conceptual framework of \textbf{Dynamic Penetrative Trajectory Adaptation (DPTA)}
represents a synthesis of three complementary AI paradigms. 
First, Penetrative AI enables contextual and semantic understanding by
leveraging large language model-based sensor comprehension for high-level intent extraction
and environmental interpretation. 
Second, the combination of Dynamic Movement Primitives (DMP) and 
Humanâ€“Robot Collaboration (HRC) contributes to adaptable trajectory generation
through shared autonomy, interactive learning, and human demonstration. 
Third, Robust Reinforcement Learning (RL) performs policy optimization and
closed-loop execution under uncertainty, ensuring real-time correction and robust action
adaptation. 
Together, these three paradigms form the foundation of the DPTA framework, enabling 
semantic reasoning, dynamic motion modification, and reliable trajectory shaping in complex 
robotic environments.



\section{Background}

The complex nature of interactive robot missions, particularly those involving high-level 
language models (LLMs) or sophisticated reinforcement learning (RL), 
presents numerous challenges across planning, learning, perception, and execution.

\subsection{Main challenges}

Limitations in High-Level Planning and Trajectory Execution (LLMs):
When LLMs are used for autonomous manipulation, they encounter issues related to generating and executing physical motions:
Inability to Handle Complex Trajectories(\cite{liu2024enhancing}) (Feasibility Issues): The conventional approach of 
using LLMs to generate code for robot motion falters when dealing with complex trajectories. 
Tasks that require intricate trajectory planning and reasoning over environments, such as 
opening an oven door featuring a horizontal axis design or opening a cabinet with a press-pull 
structure, may be deemed infeasible when relying only on the basic motion library generated by 
the LLM(\cite{liu2024enhancing}).Fragility of Prompt Design: The current design paradigm for using LLMs as controllers is 
fragile, meaning even minor alterations in the prompt can dramatically affect the performance.\cite{wang2024prompt} 
Designing a reliable prompt for robotic tasks is not yet well understood.
Executability Anomalies: Although generally high, the code generated by the LLM can 
 occasionally generate sub-tasks without assigning corresponding motion 
 functions, resulting in non-encodable and non-executable responses(\cite{liu2024enhancing}).

Issues Related to Perception and Grounding:

Successfully linking high-level instructions to the physical world introduces multiple errors:
Environmental Perception Errors and Error Accumulation: Real-world task success rates decrease 
due to error accumulation across sequential sub-tasks(\cite{liu2024enhancing}). 
Errors in environmental perception stem from inaccuracies in object detection models (
   like YOLOv5), 
such as bounding box inaccuracies, leading to slightly variable coordinates for target objects.\cite{liu2024enhancing} 
These discrepancies can cause the errors to exceed the necessary margins for precise manipulation 
(e.g., placing an apple into an oven with minimal clearance)(\cite{liu2024enhancing})
Sensor Data Processing Limitations: LLMs, when used in a "penetrative" way to analyze 
digitized sensor signals (like sequences of ECG digits), exhibit lower 
efficiency in processing extensive sequences of digital data compared to traditional methods(\cite{xu2024penetrative}).
 The hallucination rates and Mean Absolute Errors (MAEs) for some LLMs escalate with the 
 increase in window size of the input data, suggesting an inherent limitation in processing 
 extensive lengths of digitized sequences(\cite{xu2024penetrative}).
Susceptibility to Deployment Noise: Policies trained in simulation, even when using modern techniques, 
may not be robust to real-world noise. For instance, a policy trained in simulation for pick-and-place was not 
robust to small errors in box position estimation (e.g., errors with a standard deviation of 1cm) when deployed 
on a physical robot(\cite{andrychowicz2017hindsight}).

Challenges in Low-Level Control:

Controllability and Security Risks: Since LLM responses are probabilistic, there is no guarantee that the swarm will behave as intended. This also introduces new security vulnerabilities, as it needs to be studied if users or even other robots can reprogram robots through prompt injection attacks or 
if a malicious agent could send misleading information (Byzantine robot detection)(\cite{strobel2024llm2swarm}).



\subsection{ Overview: Dynamic Penetrative Trajectory Adaptation (DPTA)}

In current LLM-based manipulation, environmental information is 
primarily derived visually (e.g., YOLOv5 for object position)(\cite{liu2024enhancing}). 
However, fine-grained tasks often depend on non-visual physical 
feedback (e.g., force or torque required to open a tight hinge). 
In DPTA, the Penetrative AI(\cite{xu2024penetrative}) paradigm is employed to process digitized sensor 
signals from the robot's end effector 
(e.g., force/torque sensors, joint current feedback)


LLM's task is not to determine a broad state (like "indoors/outdoors"), 
but to execute a real-time, micro-level physical classification of the 
object/environment state during the initial phase of interaction 
(e.g., the first 100 milliseconds of grasping a handle or pushing a button)\cite{bhat2024grounding}.

Prompt Design: Our prompt utilizes the procedural guidance and fuzzy logic methods demonstrated in 
the heart rate detection task.(\cite{xu2024penetrative}) It contains a short sequence of 
raw numerical feedback (avoiding the token limit constraint associated with 
long digitized sequences) and instructs the LLM to classify the physical anomaly based on 
relative changes in the sequence.

Example Output: Based on the input torque sequence, the LLM reasoning(\cite{liu2024enhancing}) determines the precise 
physical condition, such as "Horizontal-Axis Oven Door, 
stiff hinge" or "Press-Pull Cabinet, high friction."

Dynamic Controller Role: The LLM functions as a dynamic feedback controller, selecting between:





\subsection{Literature Review}

The proposed Dynamic Penetrative Trajectory Adaptation (DPTA) framework differentiates itself from existing research in LLM-controlled robotics by addressing limitations in physical grounding, low-level trajectory execution, and robust policy learning.


High-Level Planning with Imperfect Grounding
Existing works leverage large language models (LLMs) as zero-shot planners to decompose high-level instructions (e.g., "make breakfast") 
into a sequence of actionable steps [\cite{huang2022language}]. Methods like those involving Semantic Translation improve executability 
by mapping LLM-generated phrases to the most semantically similar admissible action in a predefined set. 
SayCan grounds LLM output by weighting actions based on learned skill affordances (value functions), 
ensuring the proposed step is feasible in the current state [\cite{brohan2023can}].

Limitation: Reliance on Narrow APIs and Lack of Deep Physical Context

Despite these efforts, LLM-generated plans are still frequently not executable in interactive environments (\cite{huang2022language}) and 
struggle with mid-level grounding, often missing necessary common-sense actions [\cite{huang2022language}].    
Critically, most systems rely on predetermined vision APIs (like object detectors) to describe the scene [\cite{vemprala2024chatgpt}]. 
This focus on visual data ignores crucial non-visual physical feedback (e.g., force or torque) needed for fine-grained tasks [\cite{huang2023inner}], 
leaving the LLM policies restricted by what the perception APIs can describe [\cite{brown2020language}].

Code Generation and Trajectory Management

Recent research utilizes LLMs to directly generate policy code (Code as Policies), allowing the model to compose 
perception-to-control logic and reference external libraries (like NumPy) for complex behaviors such as spatial-geometric reasoning [\cite{liang2023code}]. 
Furthermore, LLMs have been explored as low-level feedback policies for dynamic systems like robot walking by outputting target joint positions 
directly from historical input-output sequences [\cite{liang2023code}].


Closed-Loop Adaptation and Policy Learning

Systems such as Inner Monologue and Socratic Models integrate closed-loop feedback by feeding natural language 
observations (e.g., success detection or scene description updates) back into the LLM prompt, enabling the LLM planner to reason over outcomes and 
dynamically re-plan actions [huang2023inner]. In the domain of reinforcement learning (RL), solving robotic tasks often faces the critical challenge of 
sparse and binary rewards [\cite{andrychowicz2017hindsight}].

Feedback Limitations and Learning Inefficiency

The effectiveness of closed-loop reasoning is bottlenecked by the capabilities of the low-level control policies and the fidelity of the 
language description provided by the perception system [\cite{gal2016dropout}, \cite{ebert2018internet}]. Moreover, traditional RL systems often fail in large state spaces when faced with 
sparse rewards, often necessitating tedious and domain-specific reward function engineering [\cite{andrychowicz2017hindsight}].




\section{Architecture}

The \textbf{Dynamic Penetrative Trajectory Adaptation (DPTA)} framework is a hierarchical robotic architecture that integrates large-scale language-based reasoning, physically grounded sensory interpretation, adaptive trajectory learning, and reinforcement learning. The system enables a robot to interpret natural language instructions, perceive through multimodal signals, and adapt its motion in real-world conditions (see Figure~\ref{fig:System}).

\begin{figure*}[!t]
   % also try [h], [tb], [!t], etc.
\centering
\includegraphics[width=\textwidth]{IFAC.001.png}
\caption{System demonstration}
\label{fig:System}
\end{figure*}

\[
\mathcal{A}_{\text{DPTA}} = 
\{ \mathcal{L}_{\text{plan}}, \mathcal{L}_{\text{perc}}, 
\mathcal{L}_{\text{exec}}, \mathcal{L}_{\text{learn}} \}.
\]

\subsection{High-Level Reasoning and Planning Layer}
At the highest level, a Large Language Model (LLM) acts as the cognitive planner. Given a natural-language instruction (e.g., ``open the cabinet''), the LLM performs long-horizon task decomposition and generates a structured sequence of sub-tasks. Each sub-task is mapped to motion primitives from a predefined \emph{Basic Motion Library}, enabling generalized planning without task-specific programming.

\subsection{Penetrative Perception Layer}
Unlike vision-centric pipelines, DPTA leverages \textit{Penetrative AI}~\cite{xu2024penetrative} to process raw sensor signals (e.g., joint torques, force/torque sensors). Using embedded knowledge and numerical reasoning, the LLM infers latent physical properties such as material stiffness, friction, compliance, or slippage. This enables detection of micro-level physical states that are difficult to capture visually.

\subsection{Dynamic Execution Layer}
When a task exceeds the capabilities of predefined motion primitives, DPTA employs \textit{Dynamic Movement Primitives (DMP)}~\cite{dmp} combined with \textit{Human-Robot Collaboration (HRC)}~\cite{hrc}. Demonstrated trajectories are encoded as DMPs and stored in a library for future reuse, allowing continual expansion of manipulation skills.

\subsection{Robust Learning Layer}
To ensure continuous improvement, DPTA incorporates \textit{Hindsight Experience Replay (HER)}~\cite{her}. Sparse rewards in manipulation tasks are relabeled, allowing failed trajectories to contribute to learning alternative goals. This approach improves sample efficiency and policy robustness, enabling the system to autonomously adapt over time.

\[
\text{DPTA} = \mathcal{F}\big(
    \mathcal{P}_{\text{PenAI}},\;
    \mathcal{T}_{\text{DMP/HRC}},\;
    \mathcal{R}_{\text{RRL}}
\big)
\]

---

\section{Conclusion}

This work introduces the \textbf{Dynamic Penetrative Trajectory Adaptation (DPTA)} framework, a novel architecture bridging 
high-level semantic planning and low-level dynamic control in embodied agents. While LLMs provide broad world knowledge 
capable of decomposing abstract tasks, they lack real-world experience and physical grounding, often generating plans that 
are plausible but not executable. DPTA addresses these limitations by synthesizing \textit{Penetrative AI}~\cite{xu2024penetrative}, \textit{Dynamic Movement Primitives (DMP)}~\cite{dmp}, and \textit{Hindsight Experience Replay (HER)}~\cite{her} into a cohesive system.

First, DPTA enhances perception by leveraging Penetrative AI to interpret digitized sensor signals such as force and 
torque, enabling inference of micro-level physical states (e.g., hinge stiffness, surface friction). Second,
 it addresses the limitations of rigid code generation by parameterizing DMPs through Human-Robot Collaboration (HRC), 
 ensuring kinematically sound and human-like motions. Finally, robust learning through HER allows the system to learn from failure, improving policy performance in high-dimensional state spaces.

In summary, DPTA moves beyond the ``Say'' and ``Can'' dichotomy by introducing ``Feel'' and ``Adapt''
 capabilities. By grounding semantic intent in penetrative sensory data and leveraging both stored motion primitives 
 and learned behaviors, DPTA enables embodied agents to plan logically and interact physically with nuance and adaptability.


\bibliography{ifacconf}


% A conclusion section is not required. Although a conclusion may review
% the main points of the paper, do not replicate the abstract as the
% conclusion. A conclusion might elaborate on the importance of the work
% or suggest applications and extensions.

% \begin{ack}
% Place acknowledgments here.
% \end{ack}

% \section*{DECLARATION OF GENERATIVE AI AND AI-ASSISTED TECHNOLOGIES IN THE WRITING PROCESS}
% During the preparation of this work the author(s) used [NAME TOOL / SERVICE] in order to [REASON]. After using this tool/service, the author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.
                                                   
%\begin{thebibliography}{xx}  % you can also add the bibliography by hand

%\bibitem[Able(1956)]{Abl:56}
%B.C. Able.
%\newblock Nucleic acid content of microscope.
%\newblock \emph{Nature}, 135:\penalty0 7--9, 1956.

%\bibitem[Able et~al.(1954)Able, Tagg, and Rush]{AbTaRu:54}
%B.C. Able, R.A. Tagg, and M.~Rush.
%\newblock Enzyme-catalyzed cellular transanimations.
%\newblock In A.F. Round, editor, \emph{Advances in Enzymology}, volume~2, pages
%  125--247. Academic Press, New York, 3rd edition, 1954.

%\bibitem[Keohane(1958)]{Keo:58}
%R.~Keohane.
%\newblock \emph{Power and Interdependence: World Politics in Transitions}.
%\newblock Little, Brown \& Co., Boston, 1958.

%\bibitem[Powers(1985)]{Pow:85}
%T.~Powers.
%\newblock Is there a way out?
%\newblock \emph{Harpers}, pages 35--47, June 1985.

%\bibitem[Soukhanov(1992)]{Heritage:92}
%A.~H. Soukhanov, editor.
%\newblock \emph{{The American Heritage. Dictionary of the American Language}}.
%\newblock Houghton Mifflin Company, 1992.

%\end{thebibliography}

\appendix
\section{Program}  

\begin{table}[h]
\centering
\caption{System Components and Roles in the UFactory-Based DPTA Experiment}
\begin{tabular}{p{5cm} p{8cm}}
\hline
\textbf{Component} & \textbf{Role} \\ \hline
UFactory Lite 6 & Physical execution \& HRC skill acquisition \\
UF Studio & Manual teaching with built-in recorder (joint position, velocity, gripper force) \\
UFactory Python SDK (Modbus/xArm API) & Low-level execution, feedback readout, torque and velocity streaming \\
IsaacSim + IsaacGym & Physics variability and large-scale parallel reinforcement learning \\
LLM Planner (GPT-4/5) & High-level command interpretation and motion adaptation decisions \\
DMP Encoding Module & Gaussian basis encoding of human-demonstrated motion primitives \\
\hline
\end{tabular}
\end{table}
\begin{table}[h]
\centering
\caption{System Components and Roles in the UFactory-Based DPTA Experiment}
\begin{tabular}{p{5cm} p{8cm}}
\hline
\textbf{Component} & \textbf{Role} \\ \hline
UFactory Lite 6 & Physical execution \& HRC skill acquisition \\
UF Studio & Manual teaching with built-in recorder (joint position, velocity, gripper force) \\
UFactory Python SDK (Modbus/xArm API) & Low-level execution, feedback readout, torque and velocity streaming \\
IsaacSim + IsaacGym & Physics variability and large-scale parallel reinforcement learning \\
LLM Planner (GPT-4/5) & High-level command interpretation and motion adaptation decisions \\
DMP Encoding Module & Gaussian basis encoding of human-demonstrated motion primitives \\
\hline
\end{tabular}
\end{table}












          % in the appendices.
\end{document}
